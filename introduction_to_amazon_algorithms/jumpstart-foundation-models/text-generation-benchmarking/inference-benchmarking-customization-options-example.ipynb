{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b87049bf",
   "metadata": {},
   "source": [
    "# SageMaker JumpStart Foundation Models - Benchmark Latency and Throughput"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d044d5b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "This notebook's CI test result for us-west-2 is as follows. CI test results in other regions can be found at the end of the notebook. \n",
    "\n",
    "![This us-west-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/us-west-2/introduction_to_amazon_algorithms|jumpstart-foundation-models|text-generation-benchmarking|inference-benchmarking-customization-options-example.ipynb)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6617f883",
   "metadata": {},
   "source": [
    "***\n",
    "Welcome to Amazon [SageMaker JumpStart](https://docs.aws.amazon.com/sagemaker/latest/dg/studio-jumpstart.html)! You can use SageMaker JumpStart to solve many Machine Learning tasks through one-click in SageMaker Studio, or through [SageMaker Python SDK](https://sagemaker.readthedocs.io/en/stable/overview.html#use-prebuilt-models-with-sagemaker-jumpstart).\n",
    "\n",
    "When testing a large language model for production use cases, common questions arise, such as: \n",
    "- What is the inference latency for my expected payloads?\n",
    "- How much throughput does this model configuration provide for my expected payloads?\n",
    "- What is the inference throughput and latency for my expected concurrency load, i.e., the number of concurrent requests that have invoked the endpoint?\n",
    "- How much does it cost to generate 1 million tokens?\n",
    "- How does instance type selection (e.g., `ml.g5.2xlarge`) affect latency and throughput?\n",
    "- How does modification of the deployment configuration (e.g., tensor parallel degree) affect latency and throughput?\n",
    "\n",
    "Given these questions, you may notice that inference latency and throughput depend on numerous factors, to include payload, number of concurrent requests, instance type, deployment configuration, and more. In this notebook, we demonstrate how you can run your own latency and throughput benchmark for SageMaker JumpStart endpoints. This benchmarking process involves running load tests with various concurrent request values for each payload and deployed endpoint.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78b2962e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade --quiet sagemaker transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cdf85a3",
   "metadata": {},
   "source": [
    "***\n",
    "The primary inputs to this benchmarking tool include the models to benchmark and the payloads used to invoke endpoints.\n",
    "- **`MODELS`**: A dictionary mapping a unique name to benchmarking configuration. The model can be defined in 3 different ways. Each model value should be a dictionary with the following keys:\n",
    "  - **`jumpstart_model_specs` key**: requires `model_args` and optionally `deploy_args` definitions to use with a SageMaker SDK `JumpStartModel` constructor and deploy methods, respectfully. This should be used to deploy and benchmark a JumpStart model.\n",
    "  - **`model_specs` key**: requires `image_uri_args`, `model_args`, and `deploy_args` definitions to use with a SageMaker SDK `Model` constructor and deploy methods. This should be used to deploy and benchmark a non-JumpStart model.\n",
    "  - **`endpoint_name` key**: provide the endpoint name of a pre-deployed model to benchmark.\n",
    "  - **`huggingface_model_id` key**: to compute metrics with respect to model tokens, provide the HuggingFace Model ID with an appropriate tokenizer to use.\n",
    "- **`PAYLOADS`**: A dictionary mapping a unique name to a payload of interest. The benchmarking tool will serially run a concurrency probe against each payload.\n",
    "\n",
    "For this notebook, we deploy LLama2 7B using `JumpStartModel`.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae0e7f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from benchmarking.payload import create_test_payload\n",
    "\n",
    "\n",
    "PAYLOADS = {\n",
    "    \"input_128_output_128\": create_test_payload(input_words=128, output_tokens=128),\n",
    "    # \"input_512_output_128\": create_test_payload(input_words=512, output_tokens=128),\n",
    "}\n",
    "\n",
    "# instance types: ml.g5.2xlarge, ml.g5.4xlarge, ml.g5.8xlarge, ml.g5.12xlarge, ml.g5.24xlarge, ml.g5.48xlarge, ml.p4d.24xlarge (p4 quota increase requires manual approval)\n",
    "\n",
    "MODELS = {\n",
    "\n",
    "    # DEFAULT PARAMETERS\n",
    "    \"llama2-7b-jumpstart-g5-xlarge\": {\n",
    "        \"jumpstart_model_specs\": {\"model_args\": {\"model_id\": \"meta-textgeneration-llama-2-7b-f\", \"model_version\": \"4.*\", \"instance_type\": \"ml.g5.xlarge\"}},\n",
    "        \"huggingface_model_id\": \"meta-llama/Llama-2-7b-chat\",\n",
    "    },\n",
    "    #     \"llama2-7b-jumpstart-g5-2xlarge\": {\n",
    "    #         \"jumpstart_model_specs\": {\"model_args\": {\"model_id\": \"meta-textgeneration-llama-2-7b-f\", \"model_version\": \"4.*\", \"instance_type\": \"ml.g5.2xlarge\"}},\n",
    "    #         \"huggingface_model_id\": \"meta-llama/Llama-2-7b-chat\",\n",
    "    #     },\n",
    "    #     \"llama2-7b-jumpstart-g5-4xlarge\": {\n",
    "    #         \"jumpstart_model_specs\": {\"model_args\": {\"model_id\": \"meta-textgeneration-llama-2-7b-f\", \"model_version\": \"4.*\", \"instance_type\": \"ml.g5.4xlarge\"}},\n",
    "    #         \"huggingface_model_id\": \"meta-llama/Llama-2-7b-chat\",\n",
    "    #     },\n",
    "    #     \"llama2-7b-jumpstart-g5-8xlarge\": {\n",
    "    #         \"jumpstart_model_specs\": {\"model_args\": {\"model_id\": \"meta-textgeneration-llama-2-7b-f\", \"model_version\": \"4.*\", \"instance_type\": \"ml.g5.8xlarge\"}},\n",
    "    #         \"huggingface_model_id\": \"meta-llama/Llama-2-7b-chat\",\n",
    "    #     },\n",
    "    #     \"llama2-7b-jumpstart-g5-12xlarge\": {\n",
    "    #         \"jumpstart_model_specs\": {\"model_args\": {\"model_id\": \"meta-textgeneration-llama-2-7b-f\", \"model_version\": \"4.*\", \"instance_type\": \"ml.g5.12xlarge\"}},\n",
    "    #         \"huggingface_model_id\": \"meta-llama/Llama-2-7b-chat\",\n",
    "    #     },\n",
    "    #     \"llama2-7b-jumpstart-g5-24xlarge\": {\n",
    "    #         \"jumpstart_model_specs\": {\"model_args\": {\"model_id\": \"meta-textgeneration-llama-2-7b-f\", \"model_version\": \"4.*\", \"instance_type\": \"ml.g5.24xlarge\"}},\n",
    "    #         \"huggingface_model_id\": \"meta-llama/Llama-2-7b-chat\",\n",
    "    #     },\n",
    "    #     \"llama2-7b-jumpstart-g5-48xlarge\": {\n",
    "    #         \"jumpstart_model_specs\": {\"model_args\": {\"model_id\": \"meta-textgeneration-llama-2-7b-f\", \"model_version\": \"4.*\", \"instance_type\": \"ml.g5.48xlarge\"}},\n",
    "    #         \"huggingface_model_id\": \"meta-llama/Llama-2-7b-chat\",\n",
    "    #     },\n",
    "    #     # \"llama2-7b-jumpstart-p4d-24xlarge\": {\n",
    "    #     #     \"jumpstart_model_specs\": {\"model_args\": {\"model_id\": \"meta-textgeneration-llama-2-7b-f\", \"model_version\": \"4.*\", \"instance_type\": \"ml.p4d.24xlarge\"}},\n",
    "    #     #     \"huggingface_model_id\": \"meta-llama/Llama-2-7b-chat\",\n",
    "    #     # },\n",
    "    \n",
    "    # LIMIT NUMBER OF INPUT AND OUTPUT TOKENS\n",
    "    # \"llama2-7b-jumpstart-g5-2xlarge\": {\n",
    "    #     \"jumpstart_model_specs\": {\"model_args\": {\"model_id\": \"meta-textgeneration-llama-2-7b-f\", \"model_version\": \"4.*\", \"instance_type\": \"ml.g5.2xlarge\"}},\n",
    "    #     \"huggingface_model_id\": \"meta-llama/Llama-2-7b-chat\",\n",
    "    # },\n",
    "    # \"llama2-7b-jumpstart-g5-4xlarge\": {\n",
    "    #     \"jumpstart_model_specs\": {\"model_args\": {\"model_id\": \"meta-textgeneration-llama-2-7b-f\", \"model_version\": \"4.*\", \"instance_type\": \"ml.g5.4xlarge\"}},\n",
    "    #     \"huggingface_model_id\": \"meta-llama/Llama-2-7b-chat\",\n",
    "    # },\n",
    "    # \"llama2-7b-jumpstart-g5-8xlarge\": {\n",
    "    #     \"jumpstart_model_specs\": {\"model_args\": {\"model_id\": \"meta-textgeneration-llama-2-7b-f\", \"model_version\": \"4.*\", \"instance_type\": \"ml.g5.8xlarge\"}},\n",
    "    #     \"huggingface_model_id\": \"meta-llama/Llama-2-7b-chat\",\n",
    "    # },\n",
    "    \"llama2-7b-jumpstart-g5-12xlarge-limits1\": {\n",
    "        \"jumpstart_model_specs\": {\"model_args\": {\"model_id\": \"meta-textgeneration-llama-2-7b-f\", \"model_version\": \"4.*\", \"instance_type\": \"ml.g5.12xlarge\", \"env\": {\n",
    "        \"MAX_INPUT_TOKENS\": \"192\",\n",
    "        \"MAX_TOTAL_TOKENS\": \"512\",\n",
    "        \"MAX_INPUT_LENGTH\": \"192\"\n",
    "        }}},\n",
    "        \"huggingface_model_id\": \"meta-llama/Llama-2-7b-chat\",\n",
    "        # \"endpoint_name\": \"abcdefg-NPUcqgcFgDqT\"\n",
    "    },\n",
    "    # \"llama2-7b-jumpstart-g5-24xlarge\": {\n",
    "    #     \"jumpstart_model_specs\": {\"model_args\": {\"model_id\": \"meta-textgeneration-llama-2-7b-f\", \"model_version\": \"4.*\", \"instance_type\": \"ml.g5.24xlarge\"}},\n",
    "    #     \"huggingface_model_id\": \"meta-llama/Llama-2-7b-chat\",\n",
    "    # },\n",
    "    # \"llama2-7b-jumpstart-g5-48xlarge\": {\n",
    "    #     \"jumpstart_model_specs\": {\"model_args\": {\"model_id\": \"meta-textgeneration-llama-2-7b-f\", \"model_version\": \"4.*\", \"instance_type\": \"ml.g5.48xlarge\"}},\n",
    "    #     \"huggingface_model_id\": \"meta-llama/Llama-2-7b-chat\",\n",
    "    # },\n",
    "    # \"llama2-7b-jumpstart-p4d-24xlarge\": {\n",
    "    #     \"jumpstart_model_specs\": {\"model_args\": {\"model_id\": \"meta-textgeneration-llama-2-7b-f\", \"model_version\": \"4.*\", \"instance_type\": \"ml.p4d.24xlarge\"}},\n",
    "    #     \"huggingface_model_id\": \"meta-llama/Llama-2-7b-chat\",\n",
    "    # },\n",
    "\n",
    "    # EXISTING SAGEMAKER ENDPOINTS BY NAME\n",
    "    \"llama2-7b-jumpstart-g5-12xlarge-existing\": {\n",
    "        \"jumpstart_model_specs\": {\"model_args\": {\"model_id\": \"meta-textgeneration-llama-2-7b-f\", \"model_version\": \"4.*\", \"instance_type\": \"ml.g5.12xlarge\"}},\n",
    "        \"huggingface_model_id\": \"meta-llama/Llama-2-7b-chat\",\n",
    "        \"endpoint_name\": \"bm-llama2-7b-jumpstart-g5-12xlarge-2024-10-03-09-38-08-273\"\n",
    "    },\n",
    "\n",
    "\n",
    "    # # EXISTING ENDPOINTS BY URL\n",
    "    #     \"llama2-7b-jumpstart-g5-12xlarge-url\": {\n",
    "    #         \"huggingface_model_id\": \"meta-llama/Llama-2-7b-chat\",\n",
    "    #         \"endpoint_url\": \"https://runtime.sagemaker.us-east-1.amazonaws.com/endpoints/bm-llama2-7b-jumpstart-g5-12xlarge-2024-10-03-09-38-08-273/invocations\"\n",
    "    #     },\n",
    "\n",
    "} # CLOSING BRACE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3e6064",
   "metadata": {},
   "source": [
    "***\n",
    "The default concurrency probe will iteratively produce loads to the endpoint with concurrent request values of $2^x$ for $x\\ge 0$ and stop once the endpoint produces an error, most often a SageMaker 60s endpoint invocation timeout. Here, we show how to create a custom concurrency probe iterator object with a different concurrent request schedule and an additional stop iteration criteria when latency goes above an undesirable threshold.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34f45a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "from benchmarking.concurrency_probe import ConcurrentProbeIteratorBase\n",
    "\n",
    "\n",
    "class CustomConcurrencyProbeIterator(ConcurrentProbeIteratorBase):\n",
    "    \"\"\"A custom concurrency probe iterator to explore concurrent request multiples with max latency stop criteria.\"\"\"\n",
    "\n",
    "    def __iter__(self):\n",
    "        self.concurrent_requests = 1\n",
    "        self.increment_value = 10\n",
    "        self.max_latency_per_token_ms = 100.0\n",
    "        return self\n",
    "\n",
    "    def __next__(self) -> int:\n",
    "        if self.exception is not None:\n",
    "            e = self.exception\n",
    "            self.stop_reason = \"\".join([type(e).__name__, f\": {e}\" if str(e) else \"\"])\n",
    "            raise StopIteration\n",
    "\n",
    "        if self.result is None:\n",
    "            return self.concurrent_requests\n",
    "\n",
    "        last_latency_per_token_ms = self.result[\"LatencyPerToken\"][\"p90\"]\n",
    "        if last_latency_per_token_ms > self.max_latency_per_token_ms:\n",
    "            self.stop_reason = (\n",
    "                f\"Last p90 latency = {last_latency_per_token_ms} > {self.max_latency_per_token_ms}.\"\n",
    "            )\n",
    "            raise StopIteration\n",
    "\n",
    "        self.concurrent_requests = self.concurrent_requests + self.increment_value\n",
    "\n",
    "        return self.concurrent_requests\n",
    "\n",
    "\n",
    "def num_invocation_scaler_with_minimum(\n",
    "    concurrent_requests: int, factor: int = 5, max_invocations: int = 200\n",
    ") -> int:\n",
    "    return min(concurrent_requests * factor, max_invocations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ea5e93",
   "metadata": {},
   "source": [
    "***\n",
    "Now create a `Benchmarker` object and run benchmarking for all models. This will first concurrently create a `Predictor` for all models. If `endpoint_name` is specified in the `MODELS` definition or provided in the JSON metrics file of a previous run, the endpoint will be attached to a `Predictor`. Otherwise, a new endpoint will be deployed. Once an endpoint is in service, it will begin the load test concurrency probe. A concurrency probe will be executed concurrently for all models. For each model, the probe will sweep concurrent request values, performing a load test at each unique value, until an error occurs. These errors may be validation checks (e.g., endpoint is overloaded, input sequence length unsupported, etc.), SageMaker invocation timeout, or any other potential model error. The concurrency probe for each specified payload will run serially for each model. When the probe has completed, all computed metrics will be saved in a JSON file for downstream analysis.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03977cbb-bd0c-4594-b062-8f39fffbce10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add policy to the sagemaker role: AWSPriceListServiceFullAccess\n",
    "# request access to model from HF: https://huggingface.co/meta-llama/Llama-2-7b-chat\n",
    "from huggingface_hub import notebook_login\n",
    "# notebook_login() # only once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24e41f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-03 10:58:23,301 | INFO : (Model 'llama2-7b-jumpstart-g5-xlarge'): Deploying endpoint bm-llama2-7b-jumpstart-g5-xlarge-2024-10-03-10-58-23-301 ...\n",
      "2024-10-03 10:58:23,302 | INFO : (Model 'llama2-7b-jumpstart-g5-12xlarge-limits1'): Deploying endpoint bm-llama2-7b-jumpstart-g5-12xlarge-limi-2024-10-03-10-58-23-302 ...\n",
      "2024-10-03 10:58:23,303 | INFO : (Model 'llama2-7b-jumpstart-g5-12xlarge-existing'): Predictor successfully retrieved from endpoint name\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model 'meta-textgeneration-llama-2-7b-f' requires accepting end-user license agreement (EULA). See https://jumpstart-cache-prod-us-east-1.s3.us-east-1.amazonaws.com/fmhMetadata/eula/llamaEula.txt for terms of use.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-03 10:58:23,769 | INFO : Model 'meta-textgeneration-llama-2-7b-f' requires accepting end-user license agreement (EULA). See https://jumpstart-cache-prod-us-east-1.s3.us-east-1.amazonaws.com/fmhMetadata/eula/llamaEula.txt for terms of use.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using model 'meta-textgeneration-llama-2-7b-f' with wildcard version identifier '4.*'. You can pin to version '4.7.0' for more stable results. Note that models may have different input/output signatures after a major version upgrade.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-03 10:58:23,776 | WARNING : Using model 'meta-textgeneration-llama-2-7b-f' with wildcard version identifier '4.*'. You can pin to version '4.7.0' for more stable results. Note that models may have different input/output signatures after a major version upgrade.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model 'meta-textgeneration-llama-2-7b-f' requires accepting end-user license agreement (EULA). See https://jumpstart-cache-prod-us-east-1.s3.us-east-1.amazonaws.com/fmhMetadata/eula/llamaEula.txt for terms of use.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-03 10:58:23,789 | INFO : Model 'meta-textgeneration-llama-2-7b-f' requires accepting end-user license agreement (EULA). See https://jumpstart-cache-prod-us-east-1.s3.us-east-1.amazonaws.com/fmhMetadata/eula/llamaEula.txt for terms of use.\n",
      "2024-10-03 10:58:23,797 | INFO : Creating model with name: meta-textgeneration-llama-2-7b-f-2024-10-03-10-58-23-784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using model 'meta-textgeneration-llama-2-7b-f' with wildcard version identifier '4.*'. You can pin to version '4.7.0' for more stable results. Note that models may have different input/output signatures after a major version upgrade.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-03 10:58:23,797 | WARNING : Using model 'meta-textgeneration-llama-2-7b-f' with wildcard version identifier '4.*'. You can pin to version '4.7.0' for more stable results. Note that models may have different input/output signatures after a major version upgrade.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overriding instance type to ml.g5.xlarge\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-03 10:58:23,804 | WARNING : Overriding instance type to ml.g5.xlarge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overriding instance type to ml.g5.xlarge\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-03 10:58:23,818 | WARNING : Overriding instance type to ml.g5.xlarge\n",
      "2024-10-03 10:58:23,825 | INFO : Creating model with name: meta-textgeneration-llama-2-7b-f-2024-10-03-10-58-23-804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565 - if you loaded a llama tokenizer from a GGUF file you can ignore this message\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama_fast.LlamaTokenizerFast'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565 - if you loaded a llama tokenizer from a GGUF file you can ignore this message.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-03 10:58:24,628 | INFO : Creating endpoint-config with name bm-llama2-7b-jumpstart-g5-xlarge-2024-10-03-10-58-23-301\n",
      "2024-10-03 10:58:24,845 | INFO : (Model 'llama2-7b-jumpstart-g5-12xlarge-existing', Payload 'input_128_output_128'): Begin concurrency probe ...\n",
      "2024-10-03 10:58:24,847 | INFO : (Model 'llama2-7b-jumpstart-g5-12xlarge-existing', Payload 'input_128_output_128', Concurrency 1): Begin throughput load test ...\n",
      "2024-10-03 10:58:24,866 | INFO : Creating endpoint-config with name bm-llama2-7b-jumpstart-g5-12xlarge-limi-2024-10-03-10-58-23-302\n",
      "2024-10-03 10:58:25,060 | INFO : Creating endpoint with name bm-llama2-7b-jumpstart-g5-xlarge-2024-10-03-10-58-23-301\n",
      "2024-10-03 10:58:25,229 | INFO : Creating endpoint with name bm-llama2-7b-jumpstart-g5-12xlarge-limi-2024-10-03-10-58-23-302\n",
      "2024-10-03 10:58:36,173 | INFO : (Model 'llama2-7b-jumpstart-g5-12xlarge-existing', Payload 'input_128_output_128', Concurrency 11): Begin throughput load test ...\n",
      "2024-10-03 10:58:50,564 | INFO : (Model 'llama2-7b-jumpstart-g5-12xlarge-existing', Payload 'input_128_output_128', Concurrency 21): Begin throughput load test ...\n",
      "--2024-10-03 10:59:09,555 | INFO : (Model 'llama2-7b-jumpstart-g5-12xlarge-existing', Payload 'input_128_output_128', Concurrency 31): Begin throughput load test ...\n",
      "--2024-10-03 10:59:32,154 | INFO : (Model 'llama2-7b-jumpstart-g5-12xlarge-existing', Payload 'input_128_output_128', Concurrency 41): Begin throughput load test ...\n",
      "--2024-10-03 10:59:59,398 | INFO : (Model 'llama2-7b-jumpstart-g5-12xlarge-existing', Payload 'input_128_output_128', Concurrency 51): Begin throughput load test ...\n",
      "2024-10-03 11:00:24,785 | INFO : (Model 'llama2-7b-jumpstart-g5-12xlarge-existing', Payload 'input_128_output_128', Concurrency 61): Begin throughput load test ...\n",
      "--2024-10-03 11:00:49,702 | INFO : (Model 'llama2-7b-jumpstart-g5-12xlarge-existing', Payload 'input_128_output_128', Concurrency 71): Begin throughput load test ...\n",
      "--2024-10-03 11:01:13,382 | INFO : (Model 'llama2-7b-jumpstart-g5-12xlarge-existing', Payload 'input_128_output_128', Concurrency 81): Begin throughput load test ...\n",
      "--2024-10-03 11:01:36,792 | INFO : (Model 'llama2-7b-jumpstart-g5-12xlarge-existing', Payload 'input_128_output_128', Concurrency 91): Begin throughput load test ...\n",
      "--2024-10-03 11:01:59,873 | INFO : (Model 'llama2-7b-jumpstart-g5-12xlarge-existing', Payload 'input_128_output_128', Concurrency 101): Begin throughput load test ...\n",
      "2024-10-03 11:02:22,126 | INFO : (Model 'llama2-7b-jumpstart-g5-12xlarge-existing', Payload 'input_128_output_128', Concurrency 111): Begin throughput load test ...\n",
      "--2024-10-03 11:02:44,396 | INFO : (Model 'llama2-7b-jumpstart-g5-12xlarge-existing', Payload 'input_128_output_128'): End concurrency probe. Last p90 latency = 100.10016294934415 > 100.0.\n",
      "2024-10-03 11:02:44,404 | INFO : (Model 'llama2-7b-jumpstart-g5-12xlarge-existing'): Skipping cleaning up resources ...\n",
      "--------!-2024-10-03 11:04:58,082 | INFO : (Model 'llama2-7b-jumpstart-g5-xlarge', Payload 'input_128_output_128'): Begin concurrency probe ...\n",
      "2024-10-03 11:04:58,083 | INFO : (Model 'llama2-7b-jumpstart-g5-xlarge', Payload 'input_128_output_128', Concurrency 1): Begin throughput load test ...\n",
      "2024-10-03 11:05:18,074 | INFO : (Model 'llama2-7b-jumpstart-g5-xlarge', Payload 'input_128_output_128', Concurrency 11): Begin throughput load test ...\n",
      "-2024-10-03 11:05:43,265 | INFO : (Model 'llama2-7b-jumpstart-g5-xlarge', Payload 'input_128_output_128', Concurrency 21): Begin throughput load test ...\n",
      "-2024-10-03 11:06:14,781 | INFO : (Model 'llama2-7b-jumpstart-g5-xlarge', Payload 'input_128_output_128', Concurrency 31): Begin throughput load test ...\n",
      "-2024-10-03 11:06:49,698 | INFO : (Model 'llama2-7b-jumpstart-g5-xlarge', Payload 'input_128_output_128', Concurrency 41): Begin throughput load test ...\n",
      "--2024-10-03 11:07:32,192 | INFO : (Model 'llama2-7b-jumpstart-g5-xlarge', Payload 'input_128_output_128', Concurrency 51): Begin throughput load test ...\n",
      "-2024-10-03 11:08:10,256 | INFO : (Model 'llama2-7b-jumpstart-g5-xlarge', Payload 'input_128_output_128', Concurrency 61): Begin throughput load test ...\n",
      "-2024-10-03 11:08:48,374 | INFO : (Model 'llama2-7b-jumpstart-g5-xlarge', Payload 'input_128_output_128'): End concurrency probe. Last p90 latency = 113.88043438525892 > 100.0.\n",
      "2024-10-03 11:08:48,384 | INFO : (Model 'llama2-7b-jumpstart-g5-xlarge'): Skipping cleaning up resources ...\n",
      "------------------------------*2024-10-03 11:24:00,805 | ERROR : Please check the troubleshooting guide for common errors: https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-python-sdk-troubleshooting.html#sagemaker-python-sdk-troubleshooting-create-endpoint\n",
      "2024-10-03 11:24:00,807 | ERROR : (Model 'llama2-7b-jumpstart-g5-12xlarge-limits1'): Benchmarking failed: Error hosting endpoint bm-llama2-7b-jumpstart-g5-12xlarge-limi-2024-10-03-10-58-23-302: Failed. Reason: The primary container for production variant AllTraffic did not pass the ping health check. Please check CloudWatch logs for this endpoint.. Try changing the instance type or reference the troubleshooting page https://docs.aws.amazon.com/sagemaker/latest/dg/async-inference-troubleshooting.html\n"
     ]
    }
   ],
   "source": [
    "from benchmarking.runner import Benchmarker\n",
    "\n",
    "benchmarker = Benchmarker(\n",
    "    payloads=PAYLOADS,\n",
    "    run_concurrency_probe=True,\n",
    "    concurrency_probe_concurrent_request_iterator_cls=CustomConcurrencyProbeIterator,\n",
    "    concurrency_probe_num_invocation_hook=num_invocation_scaler_with_minimum,\n",
    ")\n",
    "metrics = benchmarker.run_multiple_models(models=MODELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d6a657",
   "metadata": {},
   "source": [
    "***\n",
    "Now that benchmarking is complete, let's load the results into a Pandas DataFrame and create a pivot table that shows throughput, p90 latency, and cost to generate one million tokens. Many variations of these metrics are recorded in the DataFrame, so please extract any information relevant to your benchmarking effort.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35e12d3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"12\" halign=\"left\">throughput (tokens/s)</th>\n",
       "      <th colspan=\"12\" halign=\"left\">p90 latency (ms/token)</th>\n",
       "      <th colspan=\"12\" halign=\"left\">p90 request latency (ms)</th>\n",
       "      <th colspan=\"12\" halign=\"left\">cost to generate 1M tokens ($)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>concurrent requests</th>\n",
       "      <th>1</th>\n",
       "      <th>11</th>\n",
       "      <th>21</th>\n",
       "      <th>31</th>\n",
       "      <th>41</th>\n",
       "      <th>51</th>\n",
       "      <th>61</th>\n",
       "      <th>71</th>\n",
       "      <th>81</th>\n",
       "      <th>91</th>\n",
       "      <th>101</th>\n",
       "      <th>111</th>\n",
       "      <th>1</th>\n",
       "      <th>11</th>\n",
       "      <th>21</th>\n",
       "      <th>31</th>\n",
       "      <th>41</th>\n",
       "      <th>51</th>\n",
       "      <th>61</th>\n",
       "      <th>71</th>\n",
       "      <th>81</th>\n",
       "      <th>91</th>\n",
       "      <th>101</th>\n",
       "      <th>111</th>\n",
       "      <th>1</th>\n",
       "      <th>11</th>\n",
       "      <th>21</th>\n",
       "      <th>31</th>\n",
       "      <th>41</th>\n",
       "      <th>51</th>\n",
       "      <th>61</th>\n",
       "      <th>71</th>\n",
       "      <th>81</th>\n",
       "      <th>91</th>\n",
       "      <th>101</th>\n",
       "      <th>111</th>\n",
       "      <th>1</th>\n",
       "      <th>11</th>\n",
       "      <th>21</th>\n",
       "      <th>31</th>\n",
       "      <th>41</th>\n",
       "      <th>51</th>\n",
       "      <th>61</th>\n",
       "      <th>71</th>\n",
       "      <th>81</th>\n",
       "      <th>91</th>\n",
       "      <th>101</th>\n",
       "      <th>111</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model ID</th>\n",
       "      <th>instance type</th>\n",
       "      <th>payload</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>llama2-7b-jumpstart-g5-12xlarge-existing</th>\n",
       "      <th>ml.g5.12xlarge</th>\n",
       "      <th>input_128_output_128</th>\n",
       "      <td>59.71</td>\n",
       "      <td>515.90</td>\n",
       "      <td>736.19</td>\n",
       "      <td>926.76</td>\n",
       "      <td>993.72</td>\n",
       "      <td>1071.89</td>\n",
       "      <td>1084.19</td>\n",
       "      <td>1143.36</td>\n",
       "      <td>1166.07</td>\n",
       "      <td>1168.45</td>\n",
       "      <td>1229.00</td>\n",
       "      <td>1222.24</td>\n",
       "      <td>17</td>\n",
       "      <td>21</td>\n",
       "      <td>31</td>\n",
       "      <td>33</td>\n",
       "      <td>45</td>\n",
       "      <td>51</td>\n",
       "      <td>59</td>\n",
       "      <td>65</td>\n",
       "      <td>73</td>\n",
       "      <td>79</td>\n",
       "      <td>86</td>\n",
       "      <td>100</td>\n",
       "      <td>2,313</td>\n",
       "      <td>2,941</td>\n",
       "      <td>4,111</td>\n",
       "      <td>4,518</td>\n",
       "      <td>5,970</td>\n",
       "      <td>6,870</td>\n",
       "      <td>7,891</td>\n",
       "      <td>8,657</td>\n",
       "      <td>9,817</td>\n",
       "      <td>10,587</td>\n",
       "      <td>11,421</td>\n",
       "      <td>13,373</td>\n",
       "      <td>$32.98</td>\n",
       "      <td>$3.82</td>\n",
       "      <td>$2.68</td>\n",
       "      <td>$2.13</td>\n",
       "      <td>$1.98</td>\n",
       "      <td>$1.84</td>\n",
       "      <td>$1.82</td>\n",
       "      <td>$1.72</td>\n",
       "      <td>$1.69</td>\n",
       "      <td>$1.69</td>\n",
       "      <td>$1.60</td>\n",
       "      <td>$1.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama2-7b-jumpstart-g5-xlarge</th>\n",
       "      <th>ml.g5.xlarge</th>\n",
       "      <th>input_128_output_128</th>\n",
       "      <td>33.94</td>\n",
       "      <td>295.24</td>\n",
       "      <td>452.97</td>\n",
       "      <td>596.09</td>\n",
       "      <td>641.44</td>\n",
       "      <td>701.33</td>\n",
       "      <td>717.39</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>30</td>\n",
       "      <td>38</td>\n",
       "      <td>50</td>\n",
       "      <td>52</td>\n",
       "      <td>65</td>\n",
       "      <td>78</td>\n",
       "      <td>113</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>4,051</td>\n",
       "      <td>5,083</td>\n",
       "      <td>7,152</td>\n",
       "      <td>6,988</td>\n",
       "      <td>8,573</td>\n",
       "      <td>10,294</td>\n",
       "      <td>15,185</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>$11.52</td>\n",
       "      <td>$1.32</td>\n",
       "      <td>$0.86</td>\n",
       "      <td>$0.66</td>\n",
       "      <td>$0.61</td>\n",
       "      <td>$0.56</td>\n",
       "      <td>$0.55</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                             throughput (tokens/s)  \\\n",
       "concurrent requests                                                                              1   \n",
       "model ID                                 instance type  payload                                      \n",
       "llama2-7b-jumpstart-g5-12xlarge-existing ml.g5.12xlarge input_128_output_128  59.71                  \n",
       "llama2-7b-jumpstart-g5-xlarge            ml.g5.xlarge   input_128_output_128  33.94                  \n",
       "\n",
       "                                                                                      \\\n",
       "concurrent requests                                                               11   \n",
       "model ID                                 instance type  payload                        \n",
       "llama2-7b-jumpstart-g5-12xlarge-existing ml.g5.12xlarge input_128_output_128  515.90   \n",
       "llama2-7b-jumpstart-g5-xlarge            ml.g5.xlarge   input_128_output_128  295.24   \n",
       "\n",
       "                                                                                      \\\n",
       "concurrent requests                                                               21   \n",
       "model ID                                 instance type  payload                        \n",
       "llama2-7b-jumpstart-g5-12xlarge-existing ml.g5.12xlarge input_128_output_128  736.19   \n",
       "llama2-7b-jumpstart-g5-xlarge            ml.g5.xlarge   input_128_output_128  452.97   \n",
       "\n",
       "                                                                                      \\\n",
       "concurrent requests                                                               31   \n",
       "model ID                                 instance type  payload                        \n",
       "llama2-7b-jumpstart-g5-12xlarge-existing ml.g5.12xlarge input_128_output_128  926.76   \n",
       "llama2-7b-jumpstart-g5-xlarge            ml.g5.xlarge   input_128_output_128  596.09   \n",
       "\n",
       "                                                                                      \\\n",
       "concurrent requests                                                               41   \n",
       "model ID                                 instance type  payload                        \n",
       "llama2-7b-jumpstart-g5-12xlarge-existing ml.g5.12xlarge input_128_output_128  993.72   \n",
       "llama2-7b-jumpstart-g5-xlarge            ml.g5.xlarge   input_128_output_128  641.44   \n",
       "\n",
       "                                                                                       \\\n",
       "concurrent requests                                                                51   \n",
       "model ID                                 instance type  payload                         \n",
       "llama2-7b-jumpstart-g5-12xlarge-existing ml.g5.12xlarge input_128_output_128  1071.89   \n",
       "llama2-7b-jumpstart-g5-xlarge            ml.g5.xlarge   input_128_output_128  701.33    \n",
       "\n",
       "                                                                                       \\\n",
       "concurrent requests                                                                61   \n",
       "model ID                                 instance type  payload                         \n",
       "llama2-7b-jumpstart-g5-12xlarge-existing ml.g5.12xlarge input_128_output_128  1084.19   \n",
       "llama2-7b-jumpstart-g5-xlarge            ml.g5.xlarge   input_128_output_128  717.39    \n",
       "\n",
       "                                                                                       \\\n",
       "concurrent requests                                                                71   \n",
       "model ID                                 instance type  payload                         \n",
       "llama2-7b-jumpstart-g5-12xlarge-existing ml.g5.12xlarge input_128_output_128  1143.36   \n",
       "llama2-7b-jumpstart-g5-xlarge            ml.g5.xlarge   input_128_output_128  --        \n",
       "\n",
       "                                                                                       \\\n",
       "concurrent requests                                                                81   \n",
       "model ID                                 instance type  payload                         \n",
       "llama2-7b-jumpstart-g5-12xlarge-existing ml.g5.12xlarge input_128_output_128  1166.07   \n",
       "llama2-7b-jumpstart-g5-xlarge            ml.g5.xlarge   input_128_output_128  --        \n",
       "\n",
       "                                                                                       \\\n",
       "concurrent requests                                                                91   \n",
       "model ID                                 instance type  payload                         \n",
       "llama2-7b-jumpstart-g5-12xlarge-existing ml.g5.12xlarge input_128_output_128  1168.45   \n",
       "llama2-7b-jumpstart-g5-xlarge            ml.g5.xlarge   input_128_output_128  --        \n",
       "\n",
       "                                                                                       \\\n",
       "concurrent requests                                                               101   \n",
       "model ID                                 instance type  payload                         \n",
       "llama2-7b-jumpstart-g5-12xlarge-existing ml.g5.12xlarge input_128_output_128  1229.00   \n",
       "llama2-7b-jumpstart-g5-xlarge            ml.g5.xlarge   input_128_output_128  --        \n",
       "\n",
       "                                                                                       \\\n",
       "concurrent requests                                                               111   \n",
       "model ID                                 instance type  payload                         \n",
       "llama2-7b-jumpstart-g5-12xlarge-existing ml.g5.12xlarge input_128_output_128  1222.24   \n",
       "llama2-7b-jumpstart-g5-xlarge            ml.g5.xlarge   input_128_output_128  --        \n",
       "\n",
       "                                                                             p90 latency (ms/token)  \\\n",
       "concurrent requests                                                                               1   \n",
       "model ID                                 instance type  payload                                       \n",
       "llama2-7b-jumpstart-g5-12xlarge-existing ml.g5.12xlarge input_128_output_128  17                      \n",
       "llama2-7b-jumpstart-g5-xlarge            ml.g5.xlarge   input_128_output_128  30                      \n",
       "\n",
       "                                                                                  \\\n",
       "concurrent requests                                                           11   \n",
       "model ID                                 instance type  payload                    \n",
       "llama2-7b-jumpstart-g5-12xlarge-existing ml.g5.12xlarge input_128_output_128  21   \n",
       "llama2-7b-jumpstart-g5-xlarge            ml.g5.xlarge   input_128_output_128  38   \n",
       "\n",
       "                                                                                  \\\n",
       "concurrent requests                                                           21   \n",
       "model ID                                 instance type  payload                    \n",
       "llama2-7b-jumpstart-g5-12xlarge-existing ml.g5.12xlarge input_128_output_128  31   \n",
       "llama2-7b-jumpstart-g5-xlarge            ml.g5.xlarge   input_128_output_128  50   \n",
       "\n",
       "                                                                                  \\\n",
       "concurrent requests                                                           31   \n",
       "model ID                                 instance type  payload                    \n",
       "llama2-7b-jumpstart-g5-12xlarge-existing ml.g5.12xlarge input_128_output_128  33   \n",
       "llama2-7b-jumpstart-g5-xlarge            ml.g5.xlarge   input_128_output_128  52   \n",
       "\n",
       "                                                                                  \\\n",
       "concurrent requests                                                           41   \n",
       "model ID                                 instance type  payload                    \n",
       "llama2-7b-jumpstart-g5-12xlarge-existing ml.g5.12xlarge input_128_output_128  45   \n",
       "llama2-7b-jumpstart-g5-xlarge            ml.g5.xlarge   input_128_output_128  65   \n",
       "\n",
       "                                                                                  \\\n",
       "concurrent requests                                                           51   \n",
       "model ID                                 instance type  payload                    \n",
       "llama2-7b-jumpstart-g5-12xlarge-existing ml.g5.12xlarge input_128_output_128  51   \n",
       "llama2-7b-jumpstart-g5-xlarge            ml.g5.xlarge   input_128_output_128  78   \n",
       "\n",
       "                                                                                   \\\n",
       "concurrent requests                                                            61   \n",
       "model ID                                 instance type  payload                     \n",
       "llama2-7b-jumpstart-g5-12xlarge-existing ml.g5.12xlarge input_128_output_128  59    \n",
       "llama2-7b-jumpstart-g5-xlarge            ml.g5.xlarge   input_128_output_128  113   \n",
       "\n",
       "                                                                                  \\\n",
       "concurrent requests                                                           71   \n",
       "model ID                                 instance type  payload                    \n",
       "llama2-7b-jumpstart-g5-12xlarge-existing ml.g5.12xlarge input_128_output_128  65   \n",
       "llama2-7b-jumpstart-g5-xlarge            ml.g5.xlarge   input_128_output_128  --   \n",
       "\n",
       "                                                                                  \\\n",
       "concurrent requests                                                           81   \n",
       "model ID                                 instance type  payload                    \n",
       "llama2-7b-jumpstart-g5-12xlarge-existing ml.g5.12xlarge input_128_output_128  73   \n",
       "llama2-7b-jumpstart-g5-xlarge            ml.g5.xlarge   input_128_output_128  --   \n",
       "\n",
       "                                                                                  \\\n",
       "concurrent requests                                                           91   \n",
       "model ID                                 instance type  payload                    \n",
       "llama2-7b-jumpstart-g5-12xlarge-existing ml.g5.12xlarge input_128_output_128  79   \n",
       "llama2-7b-jumpstart-g5-xlarge            ml.g5.xlarge   input_128_output_128  --   \n",
       "\n",
       "                                                                                  \\\n",
       "concurrent requests                                                          101   \n",
       "model ID                                 instance type  payload                    \n",
       "llama2-7b-jumpstart-g5-12xlarge-existing ml.g5.12xlarge input_128_output_128  86   \n",
       "llama2-7b-jumpstart-g5-xlarge            ml.g5.xlarge   input_128_output_128  --   \n",
       "\n",
       "                                                                                   \\\n",
       "concurrent requests                                                           111   \n",
       "model ID                                 instance type  payload                     \n",
       "llama2-7b-jumpstart-g5-12xlarge-existing ml.g5.12xlarge input_128_output_128  100   \n",
       "llama2-7b-jumpstart-g5-xlarge            ml.g5.xlarge   input_128_output_128  --    \n",
       "\n",
       "                                                                             p90 request latency (ms)  \\\n",
       "concurrent requests                                                                                 1   \n",
       "model ID                                 instance type  payload                                         \n",
       "llama2-7b-jumpstart-g5-12xlarge-existing ml.g5.12xlarge input_128_output_128  2,313                     \n",
       "llama2-7b-jumpstart-g5-xlarge            ml.g5.xlarge   input_128_output_128  4,051                     \n",
       "\n",
       "                                                                                     \\\n",
       "concurrent requests                                                              11   \n",
       "model ID                                 instance type  payload                       \n",
       "llama2-7b-jumpstart-g5-12xlarge-existing ml.g5.12xlarge input_128_output_128  2,941   \n",
       "llama2-7b-jumpstart-g5-xlarge            ml.g5.xlarge   input_128_output_128  5,083   \n",
       "\n",
       "                                                                                     \\\n",
       "concurrent requests                                                              21   \n",
       "model ID                                 instance type  payload                       \n",
       "llama2-7b-jumpstart-g5-12xlarge-existing ml.g5.12xlarge input_128_output_128  4,111   \n",
       "llama2-7b-jumpstart-g5-xlarge            ml.g5.xlarge   input_128_output_128  7,152   \n",
       "\n",
       "                                                                                     \\\n",
       "concurrent requests                                                              31   \n",
       "model ID                                 instance type  payload                       \n",
       "llama2-7b-jumpstart-g5-12xlarge-existing ml.g5.12xlarge input_128_output_128  4,518   \n",
       "llama2-7b-jumpstart-g5-xlarge            ml.g5.xlarge   input_128_output_128  6,988   \n",
       "\n",
       "                                                                                     \\\n",
       "concurrent requests                                                              41   \n",
       "model ID                                 instance type  payload                       \n",
       "llama2-7b-jumpstart-g5-12xlarge-existing ml.g5.12xlarge input_128_output_128  5,970   \n",
       "llama2-7b-jumpstart-g5-xlarge            ml.g5.xlarge   input_128_output_128  8,573   \n",
       "\n",
       "                                                                                      \\\n",
       "concurrent requests                                                               51   \n",
       "model ID                                 instance type  payload                        \n",
       "llama2-7b-jumpstart-g5-12xlarge-existing ml.g5.12xlarge input_128_output_128  6,870    \n",
       "llama2-7b-jumpstart-g5-xlarge            ml.g5.xlarge   input_128_output_128  10,294   \n",
       "\n",
       "                                                                                      \\\n",
       "concurrent requests                                                               61   \n",
       "model ID                                 instance type  payload                        \n",
       "llama2-7b-jumpstart-g5-12xlarge-existing ml.g5.12xlarge input_128_output_128  7,891    \n",
       "llama2-7b-jumpstart-g5-xlarge            ml.g5.xlarge   input_128_output_128  15,185   \n",
       "\n",
       "                                                                                     \\\n",
       "concurrent requests                                                              71   \n",
       "model ID                                 instance type  payload                       \n",
       "llama2-7b-jumpstart-g5-12xlarge-existing ml.g5.12xlarge input_128_output_128  8,657   \n",
       "llama2-7b-jumpstart-g5-xlarge            ml.g5.xlarge   input_128_output_128  --      \n",
       "\n",
       "                                                                                     \\\n",
       "concurrent requests                                                              81   \n",
       "model ID                                 instance type  payload                       \n",
       "llama2-7b-jumpstart-g5-12xlarge-existing ml.g5.12xlarge input_128_output_128  9,817   \n",
       "llama2-7b-jumpstart-g5-xlarge            ml.g5.xlarge   input_128_output_128  --      \n",
       "\n",
       "                                                                                      \\\n",
       "concurrent requests                                                               91   \n",
       "model ID                                 instance type  payload                        \n",
       "llama2-7b-jumpstart-g5-12xlarge-existing ml.g5.12xlarge input_128_output_128  10,587   \n",
       "llama2-7b-jumpstart-g5-xlarge            ml.g5.xlarge   input_128_output_128  --       \n",
       "\n",
       "                                                                                      \\\n",
       "concurrent requests                                                              101   \n",
       "model ID                                 instance type  payload                        \n",
       "llama2-7b-jumpstart-g5-12xlarge-existing ml.g5.12xlarge input_128_output_128  11,421   \n",
       "llama2-7b-jumpstart-g5-xlarge            ml.g5.xlarge   input_128_output_128  --       \n",
       "\n",
       "                                                                                      \\\n",
       "concurrent requests                                                              111   \n",
       "model ID                                 instance type  payload                        \n",
       "llama2-7b-jumpstart-g5-12xlarge-existing ml.g5.12xlarge input_128_output_128  13,373   \n",
       "llama2-7b-jumpstart-g5-xlarge            ml.g5.xlarge   input_128_output_128  --       \n",
       "\n",
       "                                                                             cost to generate 1M tokens ($)  \\\n",
       "concurrent requests                                                                                       1   \n",
       "model ID                                 instance type  payload                                               \n",
       "llama2-7b-jumpstart-g5-12xlarge-existing ml.g5.12xlarge input_128_output_128  $32.98                          \n",
       "llama2-7b-jumpstart-g5-xlarge            ml.g5.xlarge   input_128_output_128  $11.52                          \n",
       "\n",
       "                                                                                     \\\n",
       "concurrent requests                                                              11   \n",
       "model ID                                 instance type  payload                       \n",
       "llama2-7b-jumpstart-g5-12xlarge-existing ml.g5.12xlarge input_128_output_128  $3.82   \n",
       "llama2-7b-jumpstart-g5-xlarge            ml.g5.xlarge   input_128_output_128  $1.32   \n",
       "\n",
       "                                                                                     \\\n",
       "concurrent requests                                                              21   \n",
       "model ID                                 instance type  payload                       \n",
       "llama2-7b-jumpstart-g5-12xlarge-existing ml.g5.12xlarge input_128_output_128  $2.68   \n",
       "llama2-7b-jumpstart-g5-xlarge            ml.g5.xlarge   input_128_output_128  $0.86   \n",
       "\n",
       "                                                                                     \\\n",
       "concurrent requests                                                              31   \n",
       "model ID                                 instance type  payload                       \n",
       "llama2-7b-jumpstart-g5-12xlarge-existing ml.g5.12xlarge input_128_output_128  $2.13   \n",
       "llama2-7b-jumpstart-g5-xlarge            ml.g5.xlarge   input_128_output_128  $0.66   \n",
       "\n",
       "                                                                                     \\\n",
       "concurrent requests                                                              41   \n",
       "model ID                                 instance type  payload                       \n",
       "llama2-7b-jumpstart-g5-12xlarge-existing ml.g5.12xlarge input_128_output_128  $1.98   \n",
       "llama2-7b-jumpstart-g5-xlarge            ml.g5.xlarge   input_128_output_128  $0.61   \n",
       "\n",
       "                                                                                     \\\n",
       "concurrent requests                                                              51   \n",
       "model ID                                 instance type  payload                       \n",
       "llama2-7b-jumpstart-g5-12xlarge-existing ml.g5.12xlarge input_128_output_128  $1.84   \n",
       "llama2-7b-jumpstart-g5-xlarge            ml.g5.xlarge   input_128_output_128  $0.56   \n",
       "\n",
       "                                                                                     \\\n",
       "concurrent requests                                                              61   \n",
       "model ID                                 instance type  payload                       \n",
       "llama2-7b-jumpstart-g5-12xlarge-existing ml.g5.12xlarge input_128_output_128  $1.82   \n",
       "llama2-7b-jumpstart-g5-xlarge            ml.g5.xlarge   input_128_output_128  $0.55   \n",
       "\n",
       "                                                                                     \\\n",
       "concurrent requests                                                              71   \n",
       "model ID                                 instance type  payload                       \n",
       "llama2-7b-jumpstart-g5-12xlarge-existing ml.g5.12xlarge input_128_output_128  $1.72   \n",
       "llama2-7b-jumpstart-g5-xlarge            ml.g5.xlarge   input_128_output_128  --      \n",
       "\n",
       "                                                                                     \\\n",
       "concurrent requests                                                              81   \n",
       "model ID                                 instance type  payload                       \n",
       "llama2-7b-jumpstart-g5-12xlarge-existing ml.g5.12xlarge input_128_output_128  $1.69   \n",
       "llama2-7b-jumpstart-g5-xlarge            ml.g5.xlarge   input_128_output_128  --      \n",
       "\n",
       "                                                                                     \\\n",
       "concurrent requests                                                              91   \n",
       "model ID                                 instance type  payload                       \n",
       "llama2-7b-jumpstart-g5-12xlarge-existing ml.g5.12xlarge input_128_output_128  $1.69   \n",
       "llama2-7b-jumpstart-g5-xlarge            ml.g5.xlarge   input_128_output_128  --      \n",
       "\n",
       "                                                                                     \\\n",
       "concurrent requests                                                             101   \n",
       "model ID                                 instance type  payload                       \n",
       "llama2-7b-jumpstart-g5-12xlarge-existing ml.g5.12xlarge input_128_output_128  $1.60   \n",
       "llama2-7b-jumpstart-g5-xlarge            ml.g5.xlarge   input_128_output_128  --      \n",
       "\n",
       "                                                                                     \n",
       "concurrent requests                                                             111  \n",
       "model ID                                 instance type  payload                      \n",
       "llama2-7b-jumpstart-g5-12xlarge-existing ml.g5.12xlarge input_128_output_128  $1.61  \n",
       "llama2-7b-jumpstart-g5-xlarge            ml.g5.xlarge   input_128_output_128  --     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "    \n",
    "import pandas as pd\n",
    "from benchmarking.runner import Benchmarker\n",
    "\n",
    "\n",
    "try:\n",
    "    df = Benchmarker.load_metrics_pandas()\n",
    "    df_pivot = Benchmarker.create_concurrency_probe_pivot_table(df)\n",
    "\n",
    "    pd.set_option(\"display.max_columns\", None)\n",
    "    pd.set_option(\"display.max_colwidth\", 0)\n",
    "    pd.set_option(\"display.max_rows\", 500)\n",
    "    display(df_pivot)\n",
    "except Exception as e:\n",
    "    print(\"Exception Error:\",e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9245a965",
   "metadata": {},
   "source": [
    "***\n",
    "Finally, please remember to clean up all model and endpoint resources to avoid incurring additional costs after your benchmarking is complete.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "754aa328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# benchmarker.clean_up_resources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2020973e-14d6-40e3-bc57-0d378ded96cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430b5632-d22d-4f7e-b5b5-3d71133566fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[[\"ModelID\",\"ConcurrentRequests\",\"Latency.p95\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3358498b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Notebook CI Test Results\n",
    "\n",
    "This notebook was tested in multiple regions. The test results are as follows, except for us-west-2 which is shown at the top of the notebook.\n",
    "\n",
    "![This us-east-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/us-east-1/introduction_to_amazon_algorithms|jumpstart-foundation-models|text-generation-benchmarking|inference-benchmarking-customization-options-example.ipynb)\n",
    "\n",
    "![This us-east-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/us-east-2/introduction_to_amazon_algorithms|jumpstart-foundation-models|text-generation-benchmarking|inference-benchmarking-customization-options-example.ipynb)\n",
    "\n",
    "![This us-west-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/us-west-1/introduction_to_amazon_algorithms|jumpstart-foundation-models|text-generation-benchmarking|inference-benchmarking-customization-options-example.ipynb)\n",
    "\n",
    "![This ca-central-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/ca-central-1/introduction_to_amazon_algorithms|jumpstart-foundation-models|text-generation-benchmarking|inference-benchmarking-customization-options-example.ipynb)\n",
    "\n",
    "![This sa-east-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/sa-east-1/introduction_to_amazon_algorithms|jumpstart-foundation-models|text-generation-benchmarking|inference-benchmarking-customization-options-example.ipynb)\n",
    "\n",
    "![This eu-west-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/eu-west-1/introduction_to_amazon_algorithms|jumpstart-foundation-models|text-generation-benchmarking|inference-benchmarking-customization-options-example.ipynb)\n",
    "\n",
    "![This eu-west-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/eu-west-2/introduction_to_amazon_algorithms|jumpstart-foundation-models|text-generation-benchmarking|inference-benchmarking-customization-options-example.ipynb)\n",
    "\n",
    "![This eu-west-3 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/eu-west-3/introduction_to_amazon_algorithms|jumpstart-foundation-models|text-generation-benchmarking|inference-benchmarking-customization-options-example.ipynb)\n",
    "\n",
    "![This eu-central-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/eu-central-1/introduction_to_amazon_algorithms|jumpstart-foundation-models|text-generation-benchmarking|inference-benchmarking-customization-options-example.ipynb)\n",
    "\n",
    "![This eu-north-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/eu-north-1/introduction_to_amazon_algorithms|jumpstart-foundation-models|text-generation-benchmarking|inference-benchmarking-customization-options-example.ipynb)\n",
    "\n",
    "![This ap-southeast-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/ap-southeast-1/introduction_to_amazon_algorithms|jumpstart-foundation-models|text-generation-benchmarking|inference-benchmarking-customization-options-example.ipynb)\n",
    "\n",
    "![This ap-southeast-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/ap-southeast-2/introduction_to_amazon_algorithms|jumpstart-foundation-models|text-generation-benchmarking|inference-benchmarking-customization-options-example.ipynb)\n",
    "\n",
    "![This ap-northeast-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/ap-northeast-1/introduction_to_amazon_algorithms|jumpstart-foundation-models|text-generation-benchmarking|inference-benchmarking-customization-options-example.ipynb)\n",
    "\n",
    "![This ap-northeast-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/ap-northeast-2/introduction_to_amazon_algorithms|jumpstart-foundation-models|text-generation-benchmarking|inference-benchmarking-customization-options-example.ipynb)\n",
    "\n",
    "![This ap-south-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/ap-south-1/introduction_to_amazon_algorithms|jumpstart-foundation-models|text-generation-benchmarking|inference-benchmarking-customization-options-example.ipynb)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
