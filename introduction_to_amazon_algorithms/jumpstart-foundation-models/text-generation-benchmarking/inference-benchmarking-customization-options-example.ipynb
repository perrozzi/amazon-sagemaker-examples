{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b87049bf",
   "metadata": {},
   "source": [
    "# SageMaker JumpStart Foundation Models - Benchmark Latency and Throughput"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d044d5b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "This notebook's CI test result for us-west-2 is as follows. CI test results in other regions can be found at the end of the notebook. \n",
    "\n",
    "![This us-west-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/us-west-2/introduction_to_amazon_algorithms|jumpstart-foundation-models|text-generation-benchmarking|inference-benchmarking-customization-options-example.ipynb)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6617f883",
   "metadata": {},
   "source": [
    "***\n",
    "Welcome to Amazon [SageMaker JumpStart](https://docs.aws.amazon.com/sagemaker/latest/dg/studio-jumpstart.html)! You can use SageMaker JumpStart to solve many Machine Learning tasks through one-click in SageMaker Studio, or through [SageMaker Python SDK](https://sagemaker.readthedocs.io/en/stable/overview.html#use-prebuilt-models-with-sagemaker-jumpstart).\n",
    "\n",
    "When testing a large language model for production use cases, common questions arise, such as: \n",
    "- What is the inference latency for my expected payloads?\n",
    "- How much throughput does this model configuration provide for my expected payloads?\n",
    "- What is the inference throughput and latency for my expected concurrency load, i.e., the number of concurrent requests that have invoked the endpoint?\n",
    "- How much does it cost to generate 1 million tokens?\n",
    "- How does instance type selection (e.g., `ml.g5.2xlarge`) affect latency and throughput?\n",
    "- How does modification of the deployment configuration (e.g., tensor parallel degree) affect latency and throughput?\n",
    "\n",
    "Given these questions, you may notice that inference latency and throughput depend on numerous factors, to include payload, number of concurrent requests, instance type, deployment configuration, and more. In this notebook, we demonstrate how you can run your own latency and throughput benchmark for SageMaker JumpStart endpoints. This benchmarking process involves running load tests with various concurrent request values for each payload and deployed endpoint.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78b2962e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade --quiet sagemaker transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cdf85a3",
   "metadata": {},
   "source": [
    "***\n",
    "The primary inputs to this benchmarking tool include the models to benchmark and the payloads used to invoke endpoints.\n",
    "- **`MODELS`**: A dictionary mapping a unique name to benchmarking configuration. The model can be defined in 3 different ways. Each model value should be a dictionary with the following keys:\n",
    "  - **`jumpstart_model_specs` key**: requires `model_args` and optionally `deploy_args` definitions to use with a SageMaker SDK `JumpStartModel` constructor and deploy methods, respectfully. This should be used to deploy and benchmark a JumpStart model.\n",
    "  - **`model_specs` key**: requires `image_uri_args`, `model_args`, and `deploy_args` definitions to use with a SageMaker SDK `Model` constructor and deploy methods. This should be used to deploy and benchmark a non-JumpStart model.\n",
    "  - **`endpoint_name` key**: provide the endpoint name of a pre-deployed model to benchmark.\n",
    "  - **`huggingface_model_id` key**: to compute metrics with respect to model tokens, provide the HuggingFace Model ID with an appropriate tokenizer to use.\n",
    "- **`PAYLOADS`**: A dictionary mapping a unique name to a payload of interest. The benchmarking tool will serially run a concurrency probe against each payload.\n",
    "\n",
    "For this notebook, we deploy LLama2 7B using `JumpStartModel`.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae0e7f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from benchmarking.payload import create_test_payload\n",
    "\n",
    "\n",
    "PAYLOADS = {\n",
    "    \"input_128_output_128\": create_test_payload(input_words=128, output_tokens=128),\n",
    "    # \"input_512_output_128\": create_test_payload(input_words=512, output_tokens=128),\n",
    "}\n",
    "\n",
    "# instance types: ml.g5.2xlarge, ml.g5.4xlarge, ml.g5.8xlarge, ml.g5.12xlarge, ml.g5.24xlarge, ml.g5.48xlarge, ml.p4d.24xlarge (p4 quota increase requires manual approval)\n",
    "\n",
    "# # ALL DEFAULT PARAMETERS\n",
    "# MODELS = {\n",
    "#     \"llama2-7b-jumpstart-g5-2xlarge\": {\n",
    "#         \"jumpstart_model_specs\": {\"model_args\": {\"model_id\": \"meta-textgeneration-llama-2-7b-f\", \"model_version\": \"3.*\", \"instance_type\": \"ml.g5.2xlarge\"}},\n",
    "#         \"huggingface_model_id\": \"meta-llama/Llama-2-7b-chat\",\n",
    "#     },\n",
    "#     \"llama2-7b-jumpstart-g5-4xlarge\": {\n",
    "#         \"jumpstart_model_specs\": {\"model_args\": {\"model_id\": \"meta-textgeneration-llama-2-7b-f\", \"model_version\": \"3.*\", \"instance_type\": \"ml.g5.4xlarge\"}},\n",
    "#         \"huggingface_model_id\": \"meta-llama/Llama-2-7b-chat\",\n",
    "#     },\n",
    "#     \"llama2-7b-jumpstart-g5-8xlarge\": {\n",
    "#         \"jumpstart_model_specs\": {\"model_args\": {\"model_id\": \"meta-textgeneration-llama-2-7b-f\", \"model_version\": \"3.*\", \"instance_type\": \"ml.g5.8xlarge\"}},\n",
    "#         \"huggingface_model_id\": \"meta-llama/Llama-2-7b-chat\",\n",
    "#     },\n",
    "#     \"llama2-7b-jumpstart-g5-12xlarge\": {\n",
    "#         \"jumpstart_model_specs\": {\"model_args\": {\"model_id\": \"meta-textgeneration-llama-2-7b-f\", \"model_version\": \"3.*\", \"instance_type\": \"ml.g5.12xlarge\"}},\n",
    "#         \"huggingface_model_id\": \"meta-llama/Llama-2-7b-chat\",\n",
    "#     },\n",
    "#     \"llama2-7b-jumpstart-g5-24xlarge\": {\n",
    "#         \"jumpstart_model_specs\": {\"model_args\": {\"model_id\": \"meta-textgeneration-llama-2-7b-f\", \"model_version\": \"3.*\", \"instance_type\": \"ml.g5.24xlarge\"}},\n",
    "#         \"huggingface_model_id\": \"meta-llama/Llama-2-7b-chat\",\n",
    "#     },\n",
    "#     \"llama2-7b-jumpstart-g5-48xlarge\": {\n",
    "#         \"jumpstart_model_specs\": {\"model_args\": {\"model_id\": \"meta-textgeneration-llama-2-7b-f\", \"model_version\": \"3.*\", \"instance_type\": \"ml.g5.48xlarge\"}},\n",
    "#         \"huggingface_model_id\": \"meta-llama/Llama-2-7b-chat\",\n",
    "#     },\n",
    "#     # \"llama2-7b-jumpstart-p4d-24xlarge\": {\n",
    "#     #     \"jumpstart_model_specs\": {\"model_args\": {\"model_id\": \"meta-textgeneration-llama-2-7b-f\", \"model_version\": \"3.*\", \"instance_type\": \"ml.p4d.24xlarge\"}},\n",
    "#     #     \"huggingface_model_id\": \"meta-llama/Llama-2-7b-chat\",\n",
    "#     # },\n",
    "# }\n",
    "\n",
    "# LIMIT NUMBER OF INPUT AND OUTPUT TOKENS\n",
    "MODELS = {\n",
    "    # \"llama2-7b-jumpstart-g5-2xlarge\": {\n",
    "    #     \"jumpstart_model_specs\": {\"model_args\": {\"model_id\": \"meta-textgeneration-llama-2-7b-f\", \"model_version\": \"3.*\", \"instance_type\": \"ml.g5.2xlarge\"}},\n",
    "    #     \"huggingface_model_id\": \"meta-llama/Llama-2-7b-chat\",\n",
    "    # },\n",
    "    # \"llama2-7b-jumpstart-g5-4xlarge\": {\n",
    "    #     \"jumpstart_model_specs\": {\"model_args\": {\"model_id\": \"meta-textgeneration-llama-2-7b-f\", \"model_version\": \"3.*\", \"instance_type\": \"ml.g5.4xlarge\"}},\n",
    "    #     \"huggingface_model_id\": \"meta-llama/Llama-2-7b-chat\",\n",
    "    # },\n",
    "    # \"llama2-7b-jumpstart-g5-8xlarge\": {\n",
    "    #     \"jumpstart_model_specs\": {\"model_args\": {\"model_id\": \"meta-textgeneration-llama-2-7b-f\", \"model_version\": \"3.*\", \"instance_type\": \"ml.g5.8xlarge\"}},\n",
    "    #     \"huggingface_model_id\": \"meta-llama/Llama-2-7b-chat\",\n",
    "    # },\n",
    "    \"llama2-7b-jumpstart-g5-12xlarge\": {\n",
    "        \"jumpstart_model_specs\": {\"model_args\": {\"model_id\": \"meta-textgeneration-llama-2-7b-f\", \"model_version\": \"3.*\", \"instance_type\": \"ml.g5.12xlarge\", \"env\": {\n",
    "        \"MAX_INPUT_TOKENS\": \"192\",\n",
    "        \"MAX_TOTAL_TOKENS\": \"512\",\n",
    "        \"MAX_INPUT_LENGTH\": \"192\"\n",
    "        }}},\n",
    "        \"huggingface_model_id\": \"meta-llama/Llama-2-7b-chat\",\n",
    "        # \"endpoint_name\": \"abcdefg-NPUcqgcFgDqT\"\n",
    "    },\n",
    "    # \"llama2-7b-jumpstart-g5-24xlarge\": {\n",
    "    #     \"jumpstart_model_specs\": {\"model_args\": {\"model_id\": \"meta-textgeneration-llama-2-7b-f\", \"model_version\": \"3.*\", \"instance_type\": \"ml.g5.24xlarge\"}},\n",
    "    #     \"huggingface_model_id\": \"meta-llama/Llama-2-7b-chat\",\n",
    "    # },\n",
    "    # \"llama2-7b-jumpstart-g5-48xlarge\": {\n",
    "    #     \"jumpstart_model_specs\": {\"model_args\": {\"model_id\": \"meta-textgeneration-llama-2-7b-f\", \"model_version\": \"3.*\", \"instance_type\": \"ml.g5.48xlarge\"}},\n",
    "    #     \"huggingface_model_id\": \"meta-llama/Llama-2-7b-chat\",\n",
    "    # },\n",
    "    # \"llama2-7b-jumpstart-p4d-24xlarge\": {\n",
    "    #     \"jumpstart_model_specs\": {\"model_args\": {\"model_id\": \"meta-textgeneration-llama-2-7b-f\", \"model_version\": \"3.*\", \"instance_type\": \"ml.p4d.24xlarge\"}},\n",
    "    #     \"huggingface_model_id\": \"meta-llama/Llama-2-7b-chat\",\n",
    "    # },\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3e6064",
   "metadata": {},
   "source": [
    "***\n",
    "The default concurrency probe will iteratively produce loads to the endpoint with concurrent request values of $2^x$ for $x\\ge 0$ and stop once the endpoint produces an error, most often a SageMaker 60s endpoint invocation timeout. Here, we show how to create a custom concurrency probe iterator object with a different concurrent request schedule and an additional stop iteration criteria when latency goes above an undesirable threshold.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34f45a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from benchmarking.concurrency_probe import ConcurrentProbeIteratorBase\n",
    "\n",
    "\n",
    "class CustomConcurrencyProbeIterator(ConcurrentProbeIteratorBase):\n",
    "    \"\"\"A custom concurrency probe iterator to explore concurrent request multiples with max latency stop criteria.\"\"\"\n",
    "\n",
    "    def __iter__(self):\n",
    "        self.concurrent_requests = 1\n",
    "        self.increment_value = 10\n",
    "        self.max_latency_per_token_ms = 100.0\n",
    "        return self\n",
    "\n",
    "    def __next__(self) -> int:\n",
    "        if self.exception is not None:\n",
    "            e = self.exception\n",
    "            self.stop_reason = \"\".join([type(e).__name__, f\": {e}\" if str(e) else \"\"])\n",
    "            raise StopIteration\n",
    "\n",
    "        if self.result is None:\n",
    "            return self.concurrent_requests\n",
    "\n",
    "        last_latency_per_token_ms = self.result[\"LatencyPerToken\"][\"p90\"]\n",
    "        if last_latency_per_token_ms > self.max_latency_per_token_ms:\n",
    "            self.stop_reason = (\n",
    "                f\"Last p90 latency = {last_latency_per_token_ms} > {self.max_latency_per_token_ms}.\"\n",
    "            )\n",
    "            raise StopIteration\n",
    "\n",
    "        self.concurrent_requests = self.concurrent_requests + self.increment_value\n",
    "\n",
    "        return self.concurrent_requests\n",
    "\n",
    "\n",
    "def num_invocation_scaler_with_minimum(\n",
    "    concurrent_requests: int, factor: int = 5, max_invocations: int = 200\n",
    ") -> int:\n",
    "    return min(concurrent_requests * factor, max_invocations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ea5e93",
   "metadata": {},
   "source": [
    "***\n",
    "Now create a `Benchmarker` object and run benchmarking for all models. This will first concurrently create a `Predictor` for all models. If `endpoint_name` is specified in the `MODELS` definition or provided in the JSON metrics file of a previous run, the endpoint will be attached to a `Predictor`. Otherwise, a new endpoint will be deployed. Once an endpoint is in service, it will begin the load test concurrency probe. A concurrency probe will be executed concurrently for all models. For each model, the probe will sweep concurrent request values, performing a load test at each unique value, until an error occurs. These errors may be validation checks (e.g., endpoint is overloaded, input sequence length unsupported, etc.), SageMaker invocation timeout, or any other potential model error. The concurrency probe for each specified payload will run serially for each model. When the probe has completed, all computed metrics will be saved in a JSON file for downstream analysis.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03977cbb-bd0c-4594-b062-8f39fffbce10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add policy to the sagemaker role: AWSPriceListServiceFullAccess\n",
    "# request access to model from HF: https://huggingface.co/meta-llama/Llama-2-7b-chat\n",
    "from huggingface_hub import notebook_login\n",
    "# notebook_login() # only once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e41f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-01 20:06:30,456 | INFO : (Model 'llama2-7b-jumpstart-g5-12xlarge'): Deploying endpoint bm-llama2-7b-jumpstart-g5-12xlarge-2024-10-01-20-06-30-456 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model 'meta-textgeneration-llama-2-7b-f' requires accepting end-user license agreement (EULA). See https://jumpstart-cache-prod-us-east-1.s3.us-east-1.amazonaws.com/fmhMetadata/eula/llamaEula.txt for terms of use.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-01 20:06:30,874 | INFO : Model 'meta-textgeneration-llama-2-7b-f' requires accepting end-user license agreement (EULA). See https://jumpstart-cache-prod-us-east-1.s3.us-east-1.amazonaws.com/fmhMetadata/eula/llamaEula.txt for terms of use.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using model 'meta-textgeneration-llama-2-7b-f' with version '3.2.0'. You can upgrade to version '4.7.0' to get the latest model specifications. Note that models may have different input/output signatures after a major version upgrade.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-01 20:06:30,878 | INFO : Using model 'meta-textgeneration-llama-2-7b-f' with version '3.2.0'. You can upgrade to version '4.7.0' to get the latest model specifications. Note that models may have different input/output signatures after a major version upgrade.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using vulnerable JumpStart model 'meta-textgeneration-llama-2-7b-f' and version '3.2.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-01 20:06:30,881 | WARNING : Using vulnerable JumpStart model 'meta-textgeneration-llama-2-7b-f' and version '3.2.0'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using model 'meta-textgeneration-llama-2-7b-f' with wildcard version identifier '3.*'. You can pin to version '3.2.0' for more stable results. Note that models may have different input/output signatures after a major version upgrade.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-01 20:06:30,883 | WARNING : Using model 'meta-textgeneration-llama-2-7b-f' with wildcard version identifier '3.*'. You can pin to version '3.2.0' for more stable results. Note that models may have different input/output signatures after a major version upgrade.\n",
      "2024-10-01 20:06:30,890 | INFO : Creating model with name: meta-textgeneration-llama-2-7b-f-2024-10-01-20-06-30-885\n",
      "2024-10-01 20:06:31,646 | INFO : Creating endpoint-config with name bm-llama2-7b-jumpstart-g5-12xlarge-2024-10-01-20-06-30-456\n",
      "2024-10-01 20:06:32,070 | INFO : Creating endpoint with name bm-llama2-7b-jumpstart-g5-12xlarge-2024-10-01-20-06-30-456\n",
      "------------------------"
     ]
    }
   ],
   "source": [
    "from benchmarking.runner import Benchmarker\n",
    "\n",
    "benchmarker = Benchmarker(\n",
    "    payloads=PAYLOADS,\n",
    "    run_concurrency_probe=True,\n",
    "    concurrency_probe_concurrent_request_iterator_cls=CustomConcurrencyProbeIterator,\n",
    "    concurrency_probe_num_invocation_hook=num_invocation_scaler_with_minimum,\n",
    ")\n",
    "metrics = benchmarker.run_multiple_models(models=MODELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d6a657",
   "metadata": {},
   "source": [
    "***\n",
    "Now that benchmarking is complete, let's load the results into a Pandas DataFrame and create a pivot table that shows throughput, p90 latency, and cost to generate one million tokens. Many variations of these metrics are recorded in the DataFrame, so please extract any information relevant to your benchmarking effort.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35e12d3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"12\" halign=\"left\">throughput (tokens/s)</th>\n",
       "      <th colspan=\"12\" halign=\"left\">p90 latency (ms/token)</th>\n",
       "      <th colspan=\"12\" halign=\"left\">p90 request latency (ms)</th>\n",
       "      <th colspan=\"12\" halign=\"left\">cost to generate 1M tokens ($)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>concurrent requests</th>\n",
       "      <th>1</th>\n",
       "      <th>11</th>\n",
       "      <th>21</th>\n",
       "      <th>31</th>\n",
       "      <th>41</th>\n",
       "      <th>51</th>\n",
       "      <th>61</th>\n",
       "      <th>71</th>\n",
       "      <th>81</th>\n",
       "      <th>91</th>\n",
       "      <th>101</th>\n",
       "      <th>111</th>\n",
       "      <th>1</th>\n",
       "      <th>11</th>\n",
       "      <th>21</th>\n",
       "      <th>31</th>\n",
       "      <th>41</th>\n",
       "      <th>51</th>\n",
       "      <th>61</th>\n",
       "      <th>71</th>\n",
       "      <th>81</th>\n",
       "      <th>91</th>\n",
       "      <th>101</th>\n",
       "      <th>111</th>\n",
       "      <th>1</th>\n",
       "      <th>11</th>\n",
       "      <th>21</th>\n",
       "      <th>31</th>\n",
       "      <th>41</th>\n",
       "      <th>51</th>\n",
       "      <th>61</th>\n",
       "      <th>71</th>\n",
       "      <th>81</th>\n",
       "      <th>91</th>\n",
       "      <th>101</th>\n",
       "      <th>111</th>\n",
       "      <th>1</th>\n",
       "      <th>11</th>\n",
       "      <th>21</th>\n",
       "      <th>31</th>\n",
       "      <th>41</th>\n",
       "      <th>51</th>\n",
       "      <th>61</th>\n",
       "      <th>71</th>\n",
       "      <th>81</th>\n",
       "      <th>91</th>\n",
       "      <th>101</th>\n",
       "      <th>111</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model ID</th>\n",
       "      <th>instance type</th>\n",
       "      <th>payload</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>llama2-7b-jumpstart-g5-12xlarge</th>\n",
       "      <th>ml.g5.12xlarge</th>\n",
       "      <th>input_128_output_128</th>\n",
       "      <td>59.97</td>\n",
       "      <td>521.64</td>\n",
       "      <td>758.99</td>\n",
       "      <td>900.73</td>\n",
       "      <td>978.79</td>\n",
       "      <td>1061.39</td>\n",
       "      <td>1070.80</td>\n",
       "      <td>1130.62</td>\n",
       "      <td>1146.87</td>\n",
       "      <td>1172.80</td>\n",
       "      <td>1214.77</td>\n",
       "      <td>1236.57</td>\n",
       "      <td>17</td>\n",
       "      <td>21</td>\n",
       "      <td>30</td>\n",
       "      <td>35</td>\n",
       "      <td>45</td>\n",
       "      <td>51</td>\n",
       "      <td>59</td>\n",
       "      <td>68</td>\n",
       "      <td>75</td>\n",
       "      <td>80</td>\n",
       "      <td>88</td>\n",
       "      <td>101</td>\n",
       "      <td>2,276</td>\n",
       "      <td>2,929</td>\n",
       "      <td>4,080</td>\n",
       "      <td>4,779</td>\n",
       "      <td>6,007</td>\n",
       "      <td>6,838</td>\n",
       "      <td>7,941</td>\n",
       "      <td>9,146</td>\n",
       "      <td>9,905</td>\n",
       "      <td>10,784</td>\n",
       "      <td>11,663</td>\n",
       "      <td>14,064</td>\n",
       "      <td>$32.84</td>\n",
       "      <td>$3.78</td>\n",
       "      <td>$2.59</td>\n",
       "      <td>$2.19</td>\n",
       "      <td>$2.01</td>\n",
       "      <td>$1.86</td>\n",
       "      <td>$1.84</td>\n",
       "      <td>$1.74</td>\n",
       "      <td>$1.72</td>\n",
       "      <td>$1.68</td>\n",
       "      <td>$1.62</td>\n",
       "      <td>$1.59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                    throughput (tokens/s)  \\\n",
       "concurrent requests                                                                     1   \n",
       "model ID                        instance type  payload                                      \n",
       "llama2-7b-jumpstart-g5-12xlarge ml.g5.12xlarge input_128_output_128  59.97                  \n",
       "\n",
       "                                                                             \\\n",
       "concurrent requests                                                      11   \n",
       "model ID                        instance type  payload                        \n",
       "llama2-7b-jumpstart-g5-12xlarge ml.g5.12xlarge input_128_output_128  521.64   \n",
       "\n",
       "                                                                             \\\n",
       "concurrent requests                                                      21   \n",
       "model ID                        instance type  payload                        \n",
       "llama2-7b-jumpstart-g5-12xlarge ml.g5.12xlarge input_128_output_128  758.99   \n",
       "\n",
       "                                                                             \\\n",
       "concurrent requests                                                      31   \n",
       "model ID                        instance type  payload                        \n",
       "llama2-7b-jumpstart-g5-12xlarge ml.g5.12xlarge input_128_output_128  900.73   \n",
       "\n",
       "                                                                             \\\n",
       "concurrent requests                                                      41   \n",
       "model ID                        instance type  payload                        \n",
       "llama2-7b-jumpstart-g5-12xlarge ml.g5.12xlarge input_128_output_128  978.79   \n",
       "\n",
       "                                                                              \\\n",
       "concurrent requests                                                       51   \n",
       "model ID                        instance type  payload                         \n",
       "llama2-7b-jumpstart-g5-12xlarge ml.g5.12xlarge input_128_output_128  1061.39   \n",
       "\n",
       "                                                                              \\\n",
       "concurrent requests                                                       61   \n",
       "model ID                        instance type  payload                         \n",
       "llama2-7b-jumpstart-g5-12xlarge ml.g5.12xlarge input_128_output_128  1070.80   \n",
       "\n",
       "                                                                              \\\n",
       "concurrent requests                                                       71   \n",
       "model ID                        instance type  payload                         \n",
       "llama2-7b-jumpstart-g5-12xlarge ml.g5.12xlarge input_128_output_128  1130.62   \n",
       "\n",
       "                                                                              \\\n",
       "concurrent requests                                                       81   \n",
       "model ID                        instance type  payload                         \n",
       "llama2-7b-jumpstart-g5-12xlarge ml.g5.12xlarge input_128_output_128  1146.87   \n",
       "\n",
       "                                                                              \\\n",
       "concurrent requests                                                       91   \n",
       "model ID                        instance type  payload                         \n",
       "llama2-7b-jumpstart-g5-12xlarge ml.g5.12xlarge input_128_output_128  1172.80   \n",
       "\n",
       "                                                                              \\\n",
       "concurrent requests                                                      101   \n",
       "model ID                        instance type  payload                         \n",
       "llama2-7b-jumpstart-g5-12xlarge ml.g5.12xlarge input_128_output_128  1214.77   \n",
       "\n",
       "                                                                              \\\n",
       "concurrent requests                                                      111   \n",
       "model ID                        instance type  payload                         \n",
       "llama2-7b-jumpstart-g5-12xlarge ml.g5.12xlarge input_128_output_128  1236.57   \n",
       "\n",
       "                                                                    p90 latency (ms/token)  \\\n",
       "concurrent requests                                                                      1   \n",
       "model ID                        instance type  payload                                       \n",
       "llama2-7b-jumpstart-g5-12xlarge ml.g5.12xlarge input_128_output_128  17                      \n",
       "\n",
       "                                                                             \\\n",
       "concurrent requests                                                  11  21   \n",
       "model ID                        instance type  payload                        \n",
       "llama2-7b-jumpstart-g5-12xlarge ml.g5.12xlarge input_128_output_128  21  30   \n",
       "\n",
       "                                                                             \\\n",
       "concurrent requests                                                  31  41   \n",
       "model ID                        instance type  payload                        \n",
       "llama2-7b-jumpstart-g5-12xlarge ml.g5.12xlarge input_128_output_128  35  45   \n",
       "\n",
       "                                                                             \\\n",
       "concurrent requests                                                  51  61   \n",
       "model ID                        instance type  payload                        \n",
       "llama2-7b-jumpstart-g5-12xlarge ml.g5.12xlarge input_128_output_128  51  59   \n",
       "\n",
       "                                                                             \\\n",
       "concurrent requests                                                  71  81   \n",
       "model ID                        instance type  payload                        \n",
       "llama2-7b-jumpstart-g5-12xlarge ml.g5.12xlarge input_128_output_128  68  75   \n",
       "\n",
       "                                                                             \\\n",
       "concurrent requests                                                  91 101   \n",
       "model ID                        instance type  payload                        \n",
       "llama2-7b-jumpstart-g5-12xlarge ml.g5.12xlarge input_128_output_128  80  88   \n",
       "\n",
       "                                                                          \\\n",
       "concurrent requests                                                  111   \n",
       "model ID                        instance type  payload                     \n",
       "llama2-7b-jumpstart-g5-12xlarge ml.g5.12xlarge input_128_output_128  101   \n",
       "\n",
       "                                                                    p90 request latency (ms)  \\\n",
       "concurrent requests                                                                        1   \n",
       "model ID                        instance type  payload                                         \n",
       "llama2-7b-jumpstart-g5-12xlarge ml.g5.12xlarge input_128_output_128  2,276                     \n",
       "\n",
       "                                                                            \\\n",
       "concurrent requests                                                     11   \n",
       "model ID                        instance type  payload                       \n",
       "llama2-7b-jumpstart-g5-12xlarge ml.g5.12xlarge input_128_output_128  2,929   \n",
       "\n",
       "                                                                            \\\n",
       "concurrent requests                                                     21   \n",
       "model ID                        instance type  payload                       \n",
       "llama2-7b-jumpstart-g5-12xlarge ml.g5.12xlarge input_128_output_128  4,080   \n",
       "\n",
       "                                                                            \\\n",
       "concurrent requests                                                     31   \n",
       "model ID                        instance type  payload                       \n",
       "llama2-7b-jumpstart-g5-12xlarge ml.g5.12xlarge input_128_output_128  4,779   \n",
       "\n",
       "                                                                            \\\n",
       "concurrent requests                                                     41   \n",
       "model ID                        instance type  payload                       \n",
       "llama2-7b-jumpstart-g5-12xlarge ml.g5.12xlarge input_128_output_128  6,007   \n",
       "\n",
       "                                                                            \\\n",
       "concurrent requests                                                     51   \n",
       "model ID                        instance type  payload                       \n",
       "llama2-7b-jumpstart-g5-12xlarge ml.g5.12xlarge input_128_output_128  6,838   \n",
       "\n",
       "                                                                            \\\n",
       "concurrent requests                                                     61   \n",
       "model ID                        instance type  payload                       \n",
       "llama2-7b-jumpstart-g5-12xlarge ml.g5.12xlarge input_128_output_128  7,941   \n",
       "\n",
       "                                                                            \\\n",
       "concurrent requests                                                     71   \n",
       "model ID                        instance type  payload                       \n",
       "llama2-7b-jumpstart-g5-12xlarge ml.g5.12xlarge input_128_output_128  9,146   \n",
       "\n",
       "                                                                            \\\n",
       "concurrent requests                                                     81   \n",
       "model ID                        instance type  payload                       \n",
       "llama2-7b-jumpstart-g5-12xlarge ml.g5.12xlarge input_128_output_128  9,905   \n",
       "\n",
       "                                                                             \\\n",
       "concurrent requests                                                      91   \n",
       "model ID                        instance type  payload                        \n",
       "llama2-7b-jumpstart-g5-12xlarge ml.g5.12xlarge input_128_output_128  10,784   \n",
       "\n",
       "                                                                             \\\n",
       "concurrent requests                                                     101   \n",
       "model ID                        instance type  payload                        \n",
       "llama2-7b-jumpstart-g5-12xlarge ml.g5.12xlarge input_128_output_128  11,663   \n",
       "\n",
       "                                                                             \\\n",
       "concurrent requests                                                     111   \n",
       "model ID                        instance type  payload                        \n",
       "llama2-7b-jumpstart-g5-12xlarge ml.g5.12xlarge input_128_output_128  14,064   \n",
       "\n",
       "                                                                    cost to generate 1M tokens ($)  \\\n",
       "concurrent requests                                                                              1   \n",
       "model ID                        instance type  payload                                               \n",
       "llama2-7b-jumpstart-g5-12xlarge ml.g5.12xlarge input_128_output_128  $32.84                          \n",
       "\n",
       "                                                                            \\\n",
       "concurrent requests                                                     11   \n",
       "model ID                        instance type  payload                       \n",
       "llama2-7b-jumpstart-g5-12xlarge ml.g5.12xlarge input_128_output_128  $3.78   \n",
       "\n",
       "                                                                            \\\n",
       "concurrent requests                                                     21   \n",
       "model ID                        instance type  payload                       \n",
       "llama2-7b-jumpstart-g5-12xlarge ml.g5.12xlarge input_128_output_128  $2.59   \n",
       "\n",
       "                                                                            \\\n",
       "concurrent requests                                                     31   \n",
       "model ID                        instance type  payload                       \n",
       "llama2-7b-jumpstart-g5-12xlarge ml.g5.12xlarge input_128_output_128  $2.19   \n",
       "\n",
       "                                                                            \\\n",
       "concurrent requests                                                     41   \n",
       "model ID                        instance type  payload                       \n",
       "llama2-7b-jumpstart-g5-12xlarge ml.g5.12xlarge input_128_output_128  $2.01   \n",
       "\n",
       "                                                                            \\\n",
       "concurrent requests                                                     51   \n",
       "model ID                        instance type  payload                       \n",
       "llama2-7b-jumpstart-g5-12xlarge ml.g5.12xlarge input_128_output_128  $1.86   \n",
       "\n",
       "                                                                            \\\n",
       "concurrent requests                                                     61   \n",
       "model ID                        instance type  payload                       \n",
       "llama2-7b-jumpstart-g5-12xlarge ml.g5.12xlarge input_128_output_128  $1.84   \n",
       "\n",
       "                                                                            \\\n",
       "concurrent requests                                                     71   \n",
       "model ID                        instance type  payload                       \n",
       "llama2-7b-jumpstart-g5-12xlarge ml.g5.12xlarge input_128_output_128  $1.74   \n",
       "\n",
       "                                                                            \\\n",
       "concurrent requests                                                     81   \n",
       "model ID                        instance type  payload                       \n",
       "llama2-7b-jumpstart-g5-12xlarge ml.g5.12xlarge input_128_output_128  $1.72   \n",
       "\n",
       "                                                                            \\\n",
       "concurrent requests                                                     91   \n",
       "model ID                        instance type  payload                       \n",
       "llama2-7b-jumpstart-g5-12xlarge ml.g5.12xlarge input_128_output_128  $1.68   \n",
       "\n",
       "                                                                            \\\n",
       "concurrent requests                                                    101   \n",
       "model ID                        instance type  payload                       \n",
       "llama2-7b-jumpstart-g5-12xlarge ml.g5.12xlarge input_128_output_128  $1.62   \n",
       "\n",
       "                                                                            \n",
       "concurrent requests                                                    111  \n",
       "model ID                        instance type  payload                      \n",
       "llama2-7b-jumpstart-g5-12xlarge ml.g5.12xlarge input_128_output_128  $1.59  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "    \n",
    "import pandas as pd\n",
    "from benchmarking.runner import Benchmarker\n",
    "\n",
    "\n",
    "try:\n",
    "    df = Benchmarker.load_metrics_pandas()\n",
    "    df_pivot = Benchmarker.create_concurrency_probe_pivot_table(df)\n",
    "\n",
    "    pd.set_option(\"display.max_columns\", None)\n",
    "    pd.set_option(\"display.max_colwidth\", 0)\n",
    "    pd.set_option(\"display.max_rows\", 500)\n",
    "    display(df_pivot)\n",
    "except Exception as e:\n",
    "    print(\"Exception Error:\",e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9245a965",
   "metadata": {},
   "source": [
    "***\n",
    "Finally, please remember to clean up all model and endpoint resources to avoid incurring additional costs after your benchmarking is complete.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "754aa328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-01 19:49:23,332 | INFO : (Model 'llama2-7b-jumpstart-g5-12xlarge'): Cleaning up resources ...\n",
      "2024-10-01 19:49:23,558 | INFO : Deleting model with name: meta-textgeneration-llama-2-7b-f-2024-10-01-19-30-51-331\n",
      "2024-10-01 19:49:23,803 | INFO : Deleting endpoint configuration with name: bm-llama2-7b-jumpstart-g5-12xlarge-2024-10-01-19-30-51-187\n",
      "2024-10-01 19:49:24,082 | INFO : Deleting endpoint with name: bm-llama2-7b-jumpstart-g5-12xlarge-2024-10-01-19-30-51-187\n"
     ]
    }
   ],
   "source": [
    "benchmarker.clean_up_resources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2020973e-14d6-40e3-bc57-0d378ded96cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430b5632-d22d-4f7e-b5b5-3d71133566fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[[\"ModelID\",\"ConcurrentRequests\",\"Latency.p95\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3358498b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Notebook CI Test Results\n",
    "\n",
    "This notebook was tested in multiple regions. The test results are as follows, except for us-west-2 which is shown at the top of the notebook.\n",
    "\n",
    "![This us-east-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/us-east-1/introduction_to_amazon_algorithms|jumpstart-foundation-models|text-generation-benchmarking|inference-benchmarking-customization-options-example.ipynb)\n",
    "\n",
    "![This us-east-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/us-east-2/introduction_to_amazon_algorithms|jumpstart-foundation-models|text-generation-benchmarking|inference-benchmarking-customization-options-example.ipynb)\n",
    "\n",
    "![This us-west-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/us-west-1/introduction_to_amazon_algorithms|jumpstart-foundation-models|text-generation-benchmarking|inference-benchmarking-customization-options-example.ipynb)\n",
    "\n",
    "![This ca-central-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/ca-central-1/introduction_to_amazon_algorithms|jumpstart-foundation-models|text-generation-benchmarking|inference-benchmarking-customization-options-example.ipynb)\n",
    "\n",
    "![This sa-east-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/sa-east-1/introduction_to_amazon_algorithms|jumpstart-foundation-models|text-generation-benchmarking|inference-benchmarking-customization-options-example.ipynb)\n",
    "\n",
    "![This eu-west-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/eu-west-1/introduction_to_amazon_algorithms|jumpstart-foundation-models|text-generation-benchmarking|inference-benchmarking-customization-options-example.ipynb)\n",
    "\n",
    "![This eu-west-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/eu-west-2/introduction_to_amazon_algorithms|jumpstart-foundation-models|text-generation-benchmarking|inference-benchmarking-customization-options-example.ipynb)\n",
    "\n",
    "![This eu-west-3 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/eu-west-3/introduction_to_amazon_algorithms|jumpstart-foundation-models|text-generation-benchmarking|inference-benchmarking-customization-options-example.ipynb)\n",
    "\n",
    "![This eu-central-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/eu-central-1/introduction_to_amazon_algorithms|jumpstart-foundation-models|text-generation-benchmarking|inference-benchmarking-customization-options-example.ipynb)\n",
    "\n",
    "![This eu-north-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/eu-north-1/introduction_to_amazon_algorithms|jumpstart-foundation-models|text-generation-benchmarking|inference-benchmarking-customization-options-example.ipynb)\n",
    "\n",
    "![This ap-southeast-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/ap-southeast-1/introduction_to_amazon_algorithms|jumpstart-foundation-models|text-generation-benchmarking|inference-benchmarking-customization-options-example.ipynb)\n",
    "\n",
    "![This ap-southeast-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/ap-southeast-2/introduction_to_amazon_algorithms|jumpstart-foundation-models|text-generation-benchmarking|inference-benchmarking-customization-options-example.ipynb)\n",
    "\n",
    "![This ap-northeast-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/ap-northeast-1/introduction_to_amazon_algorithms|jumpstart-foundation-models|text-generation-benchmarking|inference-benchmarking-customization-options-example.ipynb)\n",
    "\n",
    "![This ap-northeast-2 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/ap-northeast-2/introduction_to_amazon_algorithms|jumpstart-foundation-models|text-generation-benchmarking|inference-benchmarking-customization-options-example.ipynb)\n",
    "\n",
    "![This ap-south-1 badge failed to load. Check your device's internet connectivity, otherwise the service is currently unavailable](https://h75twx4l60.execute-api.us-west-2.amazonaws.com/sagemaker-nb/ap-south-1/introduction_to_amazon_algorithms|jumpstart-foundation-models|text-generation-benchmarking|inference-benchmarking-customization-options-example.ipynb)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
